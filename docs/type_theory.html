<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<title>Lean perfectoid spaces</title>
<link rel="canonical" href="https://leanprover-community.github.io/lean-perfectoid-spaces/" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="pygments.css">
  <script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],

    macros: {
      Prop: "{\\mathrm{Prop}}",
      Type: "{\\mathrm{Type}}",
      NN: "{\\mathbb{N}}",
      ZZ: "{\\mathbb{Z}}",
      RR: "{\\mathbb{R}}",
      F: "{\\mathscr{F}}",
      id: "{\\mathop{id}}",
      Opens: "{\\mathop{Opens}}",
      bold: ["{\\bf #1}", 1]
  }
  },
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>
  </head>
  <body>
    <section class="page-header">
	    <a href="https://leanprover-community.github.io/lean-perfectoid-spaces/"><h1 class="project-name">Lean perfectoid spaces</h1></a> <h2 class="project-tagline">by Kevin Buzzard, Johan Commelin, and Patrick Massot</h2>
      
        <a href="https://github.com/leanprover-community/lean-perfectoid-spaces" class="btn">View on GitHub</a>
    </section>

    <section class="main-content">

			<h1 id="what-are-the-foundations-of-this-project">What are the foundations of this project?</h1>
<p>Foundations of mathematics are almost entirely irrelevant to mathematicians. This is still mostly true when using a proof assistant. But of course they are very relevant to the question this page is meant to answer. Another reason to discuss foundations is they have a huge impact on how the proof assistant can fill in the implicit details of our mathematical statements. Specific examples will use the Lean theorem prover, that we used for the perfectoid spaces project. But almost everything on this page applies verbatim to Coq. Indeed, the calculus of inductive constructions (the foundational system we will briefly describe) was invented for Coq. Section 3.1 of the <a href="https://math-comp.github.io/mcb/">Mathematical Components Book</a>, and the first four chapters of <a href="https://leanprover.github.io/theorem_proving_in_lean/">Theorem Proving in Lean</a> are much longer (and much more authoritative) explanations about the same topic.</p>
<h2 id="types-and-typing-judgments">Types and typing judgments</h2>
<p>Most mathematicians that get cornered into saying something about foundations mention Zermelo-Fraenkel set theory (with or without knowing anything about that topic). This is not the kind of foundations Lean uses, it uses type theory. The main issue with set theory as a foundational framework is that it is completely unstructured. Everything is a set, and there are only two relations: equality and membership. For instance <span class="math inline">\(\pi \in \cos\)</span> is a well-formed mathematical statement (which is hopefully wrong). The huge variety of nature of mathematical objects is, from this foundational perspective, only a psychological layer that we put on top of set membership. By contrast, as indicated by its name, type theory very carefully keeps track of the type of mathematical objects. Just like every mathematicial object is a set when formalized using set theory, it is a <em>term</em> having some <em>type</em> when formalized in type theory. Type theory provides many[^1] powerful ways of combining existing types of objects into new ones. The most fundamental such combination takes two types <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> and returns the type <span class="math inline">\(A \to B\)</span> of functions from <span class="math inline">\(A\)</span> to <span class="math inline">\(B\)</span> (at this point “function” is only a name). Complicated terms are made from juxtaposition of simpler ones, and the typing rules dictate the type of any (legal) juxtaposition. For instance, if <span class="math inline">\(x\)</span> is a term with type <span class="math inline">\(A\)</span> and <span class="math inline">\(f\)</span> is a term with type <span class="math inline">\(A \to B\)</span> then <span class="math inline">\(f x\)</span>, also written as <span class="math inline">\(f(x)\)</span>, has type <span class="math inline">\(B\)</span>. It is crucial to understand that this so-called “typing judgment” happens at the meta-theoretic level, not inside the formalized theory. It does not need to be proven inside the theory, just as we don’t need to prove the rules of logic when doing regular mathematics. Since typing information is so important, there is a notation for it. We write <span class="math inline">\(x : A\)</span> to say that <span class="math inline">\(x\)</span> has type <span class="math inline">\(A\)</span>.</p>
<p>In order to easily express all of mathematics, it is important that types are allowed to depend on terms. For instance, given a term <span class="math inline">\(n\)</span> with type <span class="math inline">\(\NN\)</span>, we can form the type <span class="math inline">\(\RR^n\)</span>. Such a type is called a dependent type.</p>
<p>Up to this point, type theory is actualy closer to regular maths than set theory. What is much more exotic is how the reduction rules coming from <span class="math inline">\(\lambda\)</span>-calculus enter the game. There is a conversion relation on terms. For instance, if we consider the term <span class="math inline">\((n \mapsto 2\cdot n) : \NN \to \NN\)</span>, then the term <span class="math inline">\((n \mapsto 2\cdot n) 3\)</span> converts to <span class="math inline">\(2\cdot 3\)</span> which, by definition of multiplication, converts to <span class="math inline">\(6\)</span>. Again this happens at the meta-theoretic level, it cannot be proved or disproved inside the theory, only observed.<br />
Together with the typing rule given above, this conversion rule justifies the name “function type”. We will say that <span class="math inline">\((n \mapsto 2 \cdot n) 3\)</span> is <em>definitionally</em> equal to <span class="math inline">\(6\)</span>. In this page, this word will always be used in this very specific technical sense.</p>
<p>Unfortunately, computer scientists have strong emotional bounds to a very weird way of denoting functions like <span class="math inline">\(n \mapsto 2\cdot n\)</span>. They write it as <span class="math inline">\(\lambda\, n, 2\cdot n\)</span> or, when they need to make the variable type explicit, <span class="math inline">\(\lambda\, n : \NN, 2\cdot n\)</span>. Getting used to that is surprisingly not so hard.</p>
<h2 id="curry-howard-and-proofs">Curry-Howard and proofs</h2>
<p>Applying typing rules is the core activity of a proof assistant based on type theory (such as Lean), and it is done by the so-called <em>kernel</em>. Remarkably, this includes checking proofs, thanks to the Curry-Howard isomorphism, as we will now explain. Each mathematical statement is also a type of mathematical object, and a proof of such a statement is a term having this type. Proof checking is thus a particular kind of typing judgment. For instance, if <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> are statements, then the statement <span class="math inline">\(P \implies Q\)</span> is the function type <span class="math inline">\(P \to Q\)</span>. Indeed there is no need to introduce a new typing judgment since we want exactly the same rule as above: given <span class="math inline">\(h_P : P\)</span> (i.e. <span class="math inline">\(h_P\)</span> is a term of type <span class="math inline">\(P\)</span>, i.e. <span class="math inline">\(h_P\)</span> a proof of <span class="math inline">\(P\)</span>) and <span class="math inline">\(h : P \to Q\)</span> (i.e. <span class="math inline">\(h\)</span> is a proof that <span class="math inline">\(P\)</span> implies <span class="math inline">\(Q\)</span>) then <span class="math inline">\(h\, h_P : Q\)</span> (ie. <span class="math inline">\(h\, h_P\)</span> is a proof of <span class="math inline">\(Q\)</span>).</p>
<p>Type themselves live in so-called universes. Universes forms a countable sequence. This is necessary in order to avoid paradoxes analogous to Russell’s barber paradox in set theory, but this kind of consideration is not relevant to us. More importantly, this allows to see types as terms. Mathematical statements are types whose universe is called <span class="math inline">\(\Prop\)</span>. Usual mathematical types, like <span class="math inline">\(\NN\)</span> or <span class="math inline">\(\RR\)</span> have universe <span class="math inline">\(\Type\)</span>. Using this and dependent types, we can now express the idea of a predicates, i.e. mathematical statement depending on a mathematical object. For instance, being even is a predicate depending on a natural number, hence it has type <span class="math inline">\(\NN \to \Prop\)</span>. For any given natural number <span class="math inline">\(n\)</span>, we get the type <span class="math inline">\(\mathrm{even}(n) : \Prop\)</span>, and a term of type <span class="math inline">\(\mathrm{even}(n)\)</span> is a proof that <span class="math inline">\(n\)</span> is even.</p>
<p>In order to express the universal quantifier, one needs a mild generalization of function types, where the target type can depend on the input value. There are sometimes called dependent function types. For instance, a proof of the statement <span class="math inline">\(\forall n, \mathrm{even(2n)}\)</span> is seen as the function sending a natural number <span class="math inline">\(n\)</span> to a proof that <span class="math inline">\(2n\)</span> is even. Say we have a proof of this statement, ie a term <span class="math inline">\(\mathrm{double\_even} : \forall n, \mathrm{even(2n)}\)</span>, and a term <span class="math inline">\(\mathrm{succ\_odd} : \forall n, \mathrm{even}(n) \to \mathrm{odd(n+1)}\)</span>. We now want to use those to prove that, for every <span class="math inline">\(n\)</span>, <span class="math inline">\(2n+1\)</span> is odd. It means we need a term whose type is <span class="math inline">\(\forall n, \mathrm{odd(2n+1)}\)</span>, ie a function with input <span class="math inline">\(n\)</span> and output a proof that <span class="math inline">\(2n+1\)</span> is odd. Given any <span class="math inline">\(n\)</span>, it suffices to apply <span class="math inline">\(\mathrm{succ\_odd}\)</span> to <span class="math inline">\(2n\)</span> and a proof that <span class="math inline">\(2n\)</span> is even. And <span class="math inline">\(\mathrm{double\_even}\, n\)</span> is precisely the latter. So our full proof term is <span class="math inline">\(n \mapsto \mathrm{succ\_odd}\; 2n\; (\mathrm{double\_even}\, n)\)</span>. This is almost valid Lean code, we only need to remember to use <span class="math inline">\(\lambda\)</span> instead of <span class="math inline">\(\mapsto\)</span>, and also remember computers don’t like implicit multiplication.</p>
<div class="highlight"><pre><span></span><span class="kd">lemma</span> <span class="n">test</span> <span class="o">:</span> <span class="bp">∀</span> <span class="n">n</span><span class="o">,</span> <span class="n">odd</span> <span class="o">(</span><span class="mi">2</span><span class="bp">*</span><span class="n">n</span> <span class="bp">+</span> <span class="mi">1</span><span class="o">)</span> <span class="o">:=</span>
<span class="bp">λ</span> <span class="n">n</span><span class="o">,</span> <span class="n">odd_succ</span> <span class="o">(</span><span class="mi">2</span><span class="bp">*</span><span class="n">n</span><span class="o">)</span> <span class="o">(</span><span class="n">double_even</span> <span class="n">n</span><span class="o">)</span>
</pre></div>

<p>Now, you may wonder how Lean know that <span class="math inline">\(n\)</span> has type <span class="math inline">\(\NN\)</span> in the above snippet. This is already using the benefits of carefully tracking the types of mathematical objects. Indeed, we assumed above that <span class="math inline">\(\mathrm{even}\)</span> and <span class="math inline">\(\mathrm{odd}\)</span> have type <span class="math inline">\(\NN \to \Prop\)</span>, so Lean can infer that, in the statement, <code>2*n + 1</code> necessarily has type <span class="math inline">\(\NN\)</span>, and then so does <code>n</code>. The same reasonning allows us to start the proof term with <code>λ n</code> instead of <code>λ n : ℕ</code>. This so-called unification procedure is actually much more powerful. For instance, one can leave holes using <code>_</code> wherever a term is expected, and Lean will try to fill this hole by unification. In our example, we could have written:</p>
<div class="highlight"><pre><span></span><span class="kd">lemma</span> <span class="n">test</span> <span class="o">:</span> <span class="bp">∀</span> <span class="n">n</span><span class="o">,</span> <span class="n">odd</span> <span class="o">(</span><span class="mi">2</span><span class="bp">*</span><span class="n">n</span> <span class="bp">+</span> <span class="mi">1</span><span class="o">)</span> <span class="o">:=</span>
<span class="bp">λ</span> <span class="n">n</span><span class="o">,</span> <span class="n">odd_succ</span> <span class="n">_</span> <span class="o">(</span><span class="n">double_even</span> <span class="n">_</span><span class="o">)</span>
</pre></div>

<p>The first hole is filled by unifying the expected type <code>odd (2*n + 1)</code> with the type of <code>odd_succ _</code> which is <code>even ?₁ → odd (?₁+1)</code> for some unknown <code>?₁</code>. This first unification succeeds by setting <code>?₁ = 2*n</code>. Then Lean needs to unify the type <code>even (2*?₂)</code> of <code>double_even _</code> with the expected <code>even (2*n)</code> and again there is only one solution, which is <code>?₂ = n</code>. Of course we don’t gain much in the simple example, but unification is crucial in more complicated examples.</p>
<p>One should note that the unification process is not part of the kernel. The kernel (which needs to be trusted, hence very simple) receives the fully elaborated term <code>λ n : ℕ, odd_succ (2*n) (double_even n)</code>, applies typing rules to compute its type, and compares with the fully elaborated statement <code>∀ n : ℕ, odd (2*n + 1)</code>. This process is so much simpler than being a full proof assistant that there are at least three alternative checkers, written in three different programming languages (Lean itself is written in C++, and there are checkers written in Haskell, Scala, and Rust).</p>
<p>Even with good elaboration, writing proof terms by hand very quickly becomes unsustainable. There is a huge layer called the tactic framework whose role is to interact with the user, and write proof terms off stage. For example, it takes a very long time to prove from first principles that <span class="math inline">\((a+b)^3=a^3+3ab^2+3ab^2+b^3\)</span> for integers <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, the main problem being that re-arranging the sum of eight terms using only commutativity and associativity is incredibly tedious for a human. However Lean’s <code>ring</code> tactic produces a proof of this immediately without the user having to worry about doing it by hand. Again this tactic layer is not trusted, it builds terms whose type is checked by the kernel. To put it another way, tactics create candidates for proofs, and then the kernel checks that they are actually correct proofs.</p>
<h2 id="inductive-types">Inductive types</h2>
<p>We haven’t yet described enough ways to build types. For instance, we haven’t seen have to build the type <span class="math inline">\(\NN\)</span>. Surprisingly related, we have explained universal quantifiers, but not existential ones, conjunctions and disjunctions. All those things are inductive types.</p>
<p>The following is Lean’s definition of natural number, following Peano’s axioms:</p>
<div class="highlight"><pre><span></span><span class="kd">inductive</span> <span class="n">ℕ</span>
<span class="bp">|</span> <span class="n">zero</span> <span class="o">:</span> <span class="n">ℕ</span>
<span class="bp">|</span> <span class="n">succ</span> <span class="o">:</span> <span class="n">ℕ</span> <span class="bp">→</span> <span class="n">ℕ</span>
</pre></div>

<p>It reads: there are exactly two ways to build a term of type <code>ℕ</code>, either the constant <code>zero</code>, or apply the function <code>succ</code> to a term with type <code>ℕ</code>. Implicitly, it also says that those two ways are unrelated (in particular it guarantees that <code>zero</code> is not equal to <code>succ n</code> for any <code>n</code>).</p>
<p>Remember that, deep down, the only things that exist are terms and types, and, at the meta-theoretic level, typing judgments and term conversions (aka definitional equality).</p>
<p>The definition does a number of those deep things. Visibly, it postulates the existence of two terms <code>zero : ℕ</code> and <code>succ : ℕ → ℕ</code>. But it also postulate the existence of the corresponding induction principle. This is a term whose type is a bit complicated, but the important thing is it allows to recover the usual proof by induction principle (if, for some predicate <span class="math inline">\(P\)</span> on <span class="math inline">\(\NN\)</span>, <span class="math inline">\(P\, 0\)</span> holds and <span class="math inline">\(P\, d \implies P\, (succ\, d)\)</span> then <span class="math inline">\(P\, n\)</span> hold for all <span class="math inline">\(n\)</span>) and the possibility of defining sequences by induction (given <span class="math inline">\(u_0\)</span> and the constraint <span class="math inline">\(u_{n+1} = f(u_n)\)</span>).</p>
<p>Again this is much closer to mathematical intuition than building a model of Peano’s axioms in ZF set theory.</p>
<p>More generally, inductive types can take parameters (there is none in our example), have arbitrarily many “constructors” (here there are two: <code>zero</code> and <code>succ</code>) which can take arbitrarily many arguments (no argument in the case of <code>zero</code> and one argument in the case of <code>succ</code>). These arguments can be terms of the type being defined (as in <code>succ</code>), modulo some technical condition which prevents circular constructions.</p>
<p>Amazingly, together with dependent function types, inductive types allow to build everything else. For instance, amongst logical operations, we have described only implication and the <span class="math inline">\(\forall\)</span> quantifier. Everything else is defined using inductive types. For instance, the definition of the logical operation “and” is:</p>
<div class="highlight"><pre><span></span><span class="kd">inductive</span> <span class="n">And</span> <span class="o">(</span><span class="n">P</span> <span class="n">Q</span> <span class="o">:</span> <span class="kt">Prop</span><span class="o">)</span> <span class="o">:</span>
<span class="bp">|</span> <span class="n">intro</span> <span class="o">(</span><span class="n">h</span> <span class="o">:</span> <span class="n">P</span><span class="o">)</span> <span class="o">(</span><span class="n">h&#39;</span> <span class="o">:</span> <span class="n">Q</span><span class="o">)</span> <span class="o">:</span> <span class="n">And</span>
</pre></div>

<p>It says that, for any two statements <code>P</code> and <code>Q</code>, one can define an inductive type <code>And P Q</code>, and the only way to build a term having this type is to use the function <code>intro</code> which takes a proof <code>h</code> of <code>P</code> and a proof <code>h'</code> of <code>Q</code>. The corresponding induction principle guarantees that we can do something using a term whose type is <code>And P Q</code> if we can do it with the ingredients taken by <code>intro</code>.</p>
<p>As an exercise, you can think about the definition of the “or” operator:</p>
<div class="highlight"><pre><span></span><span class="kd">inductive</span> <span class="n">Or</span> <span class="o">(</span><span class="n">P</span> <span class="n">Q</span> <span class="o">:</span> <span class="kt">Prop</span><span class="o">)</span> <span class="o">:</span>
<span class="bp">|</span> <span class="n">left</span> <span class="o">(</span><span class="n">h</span> <span class="o">:</span> <span class="n">P</span><span class="o">)</span> <span class="o">:</span> <span class="n">Or</span>
<span class="bp">|</span> <span class="n">right</span> <span class="o">(</span><span class="n">h&#39;</span> <span class="o">:</span> <span class="n">Q</span><span class="o">)</span> <span class="o">:</span> <span class="n">Or</span>
</pre></div>

<p>Note that this time we have two constructors, and hence two ways of constructing a term of type <code>Or P Q</code>.</p>
<p>Surprisingly, even equality is not a primitive notion in these foundations, and is defined as an inductive type. Now we can finally point out the deepest difference between foundations based on set theory and type theory. In order to use set theory, one needs to have developped (first order) logic, with its logical connective and deduction rules. And then proofs have nothing in common with mathematical objects, they live purely at the meta-theoretic level. In dependent type theory with inductive types, logic is expressed inside the theory, and proofs are mathematical objects living inside the theory.</p>
<p>Inductive types also allow us to define structures. For instance, a commutative magma structure on a type <span class="math inline">\(M\)</span> is made of a multiplication operation and the assertion that this multiplication is commutative. Multiplication <code>mul</code> takes two terms with type <span class="math inline">\(M\)</span> and returns a term with type <span class="math inline">\(M\)</span>.</p>
<div class="highlight"><pre><span></span><span class="kd">inductive</span> <span class="n">comm_magma</span> <span class="o">(</span><span class="n">M</span> <span class="o">:</span> <span class="kt">Type</span><span class="o">)</span>
<span class="bp">|</span> <span class="n">make</span> <span class="o">(</span><span class="n">mul</span> <span class="o">:</span> <span class="n">M</span> <span class="bp">×</span> <span class="n">M</span> <span class="bp">→</span> <span class="n">M</span><span class="o">)</span> <span class="o">(</span><span class="n">comm</span> <span class="o">:</span> <span class="bp">∀</span> <span class="n">a</span> <span class="n">b</span> <span class="o">:</span> <span class="n">M</span><span class="o">,</span> <span class="n">mul</span> <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="bp">=</span> <span class="n">mul</span> <span class="o">(</span><span class="n">b</span><span class="o">,</span> <span class="n">a</span><span class="o">))</span> <span class="o">:</span> <span class="n">comm_magma</span>
</pre></div>

<p>Here the constructor is called <code>make</code>, it says to build a term whose type is <code>comm_magma M</code> we need exactly a function <code>mul : M × M → M</code> and a term <code>comm</code> proving that this operation is commutative. The induction principle says that anything which follows from those ingredients follows from having fixed a commutative monoid structure on <code>M</code>. Of course Lean provides many facilities in order to define and use such structures, including facilities for building rich structures extending simpler ones, but this does not change anything about these foundations.</p>
<h2 id="the-axiom-of-choice-and-computation"> The axiom of choice and computation</h2>
<p>One often reads that proof assistant users love constructive mathematics and don’t like the axiom of choice. A much better approximation of the truth is that some users of proof assistants have those tastes. Proof assistants that we know have no issue at all postulating the axiom of choice, and Lean users in general don’t even notice when they use it (although Lean does report it if asked about it). Using the axiom of choice in some code might make the corresponding functions noncomputable. However many mathematicians are often far more concerned with reasoning about functions (that is, proving theorems about them) than actually computing them, and so noncomputability is not an issue in practice.</p>

      <footer class="site-footer">
          <span class="site-footer-owner"><a href="https://github.com/leanprover-community/lean-perfectoid-spaces">lean-perfectoid-spaces</a> is maintained by <a href="https://github.com/leanprover-community">leanprover-community</a>.</span>
        
      </footer>
    </section>
  </body>
</html>

